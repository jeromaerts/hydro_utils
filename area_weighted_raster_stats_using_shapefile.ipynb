{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350bf4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import iris\n",
    "import iris.pandas\n",
    "from esmvalcore import preprocessor\n",
    "from pathos.threading import ThreadPool as Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b0d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths (Shown are for Snellius HPC)\n",
    "SHAPE_DIR = \"/gpfs/home6/jaerts/fransje_code/catchment_shapefiles/\"\n",
    "NC4_DIR = \"/gpfs/home6/jaerts/fransje_code/GSWP3-data/\"\n",
    "OUT_DIR = \"/gpfs/home6/jaerts/fransje_code/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648b7809-70c8-42e6-9712-e86d7dc3ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_weighted_shapefile_rasterstats(\n",
    "    catchment_shapefile,\n",
    "    catchment_netcdf,\n",
    "    statistical_operator,\n",
    "    output_dir,\n",
    "    output_csv=False,\n",
    "    return_cube=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate area weighted zonal statistics of netcdfs using a shapefile to extract netcdf data.\n",
    "\n",
    "    catchment_shapefile:  str, catchment shapefile\n",
    "    catchment_netcdf:     str, netcdf file\n",
    "    statistical_operator: str, (mean (NOT area weighted), median (NOT area weighted), sum, variance, min, max, rms)\n",
    "    - https://docs.esmvaltool.org/projects/esmvalcore/en/latest/api/esmvalcore.preprocessor.html#esmvalcore.preprocessor.area_statistics\n",
    "    output_csv:          bool, True stores csv output and False stores netcdf output\n",
    "\n",
    "    Returns: iris cube, stores .csv file or .nc file\n",
    "    \"\"\"\n",
    "    # Load iris cube of netcdf\n",
    "    cube = iris.load_cube(catchment_netcdf)\n",
    "\n",
    "    # From cube extract shapefile shape\n",
    "    cube = preprocessor.extract_shape(cube, catchment_shapefile)\n",
    "\n",
    "    # Calculate area weighted statistics\n",
    "    cube_stats = preprocessor.area_statistics(cube, statistical_operator)\n",
    "\n",
    "    if output_csv is True:\n",
    "        # Convert cube to dataframe\n",
    "        df = iris.pandas.as_data_frame(cube_stats)\n",
    "\n",
    "        # Change column names\n",
    "        df = df.reset_index()\n",
    "        df = df.set_axis([\"time\", cube_stats.name()], axis=1)\n",
    "\n",
    "        # Write csv as output\n",
    "        df.to_csv(\n",
    "            f\"{output_dir}/{Path(catchment_shapefile).name.split('.')[0]}_{catchment_netcdf.split('/')[-1].split('_')[0]}_{statistical_operator}.csv\"\n",
    "        )\n",
    "    else:\n",
    "        iris.save(\n",
    "            cube_stats,\n",
    "            f\"{output_dir}/{Path(catchment_shapefile).name.split('.')[0]}_{catchment_netcdf.split('/')[-1].split('_')[0]}_{statistical_operator}.nc\",\n",
    "        )\n",
    "\n",
    "    if return_cube == True:\n",
    "        return cube\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56951c22-fcca-44b5-a286-8010ff88cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_function_parallel(\n",
    "    shapefile_list=list,\n",
    "    netcdf_list=list,\n",
    "    operator_list=list,\n",
    "    output_dir_list=list,\n",
    "    threads=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs function area_weighted_shapefile_rasterstats in parallel.\n",
    "\n",
    "    shapefile_list:  str, list, list of input catchment shapefiles\n",
    "    netcdf_list:     str, list, list of input netcdf files\n",
    "    operator_list:   str, list, list of statistical operators (single operator)\n",
    "    output_dir_list: str, list, list of output directories\n",
    "    threads:         int,       number of threads (cores), when set to None use all available threads\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    # Set number of threads (cores) used for parallel run and map threads\n",
    "    if threads is None:\n",
    "        pool = Pool()\n",
    "    else:\n",
    "        pool = Pool(nodes=threads)\n",
    "    # Run parallel models\n",
    "    results = pool.map(\n",
    "        area_weighted_shapefile_rasterstats,\n",
    "        shapefile_list,\n",
    "        netcdf_list,\n",
    "        operator_list,\n",
    "        output_dir_list,\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d7e09db-c921-4477-ab0a-235ac0d11b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_lists_for_parallel_function(NC4_DIR, SHAPE_DIR, OUT_DIR):\n",
    "    \"\"\"\n",
    "    This functions constructs list for running code in parallel.\n",
    "\n",
    "    NC4_DIR:              str, dir containing input netcdf files for area weighted statitic calculations\n",
    "    SHAPE_DIR:            str, dir containing catchment shapefiles\n",
    "    OUT_DIR:              str, dir for output storage\n",
    "\n",
    "    Returns: list of netcdfs, shapefiles, output directories\n",
    "    \"\"\"\n",
    "    netcdfs = glob.glob(f\"{NC4_DIR}/*nc\")\n",
    "    shapefiles = glob.glob(f\"{SHAPE_DIR}/*shp\")\n",
    "\n",
    "    output_dir = [OUT_DIR]\n",
    "\n",
    "    shapefile_list = shapefiles * len(netcdfs)\n",
    "    shapefile_list.sort()\n",
    "    netcdf_list = netcdfs * len(shapefiles)\n",
    "    output_dir_list = output_dir * len(shapefile_list)\n",
    "\n",
    "    operator_list = []\n",
    "\n",
    "    for netcdf in netcdf_list:\n",
    "        if \"tas\" in netcdf:\n",
    "            operator_list.append(\"mean\")\n",
    "        else:\n",
    "            operator_list.append(\"sum\")\n",
    "\n",
    "    return shapefile_list, netcdf_list, operator_list, output_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f178c3-450f-4584-876b-487dbc8bbc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct lists for parallel run\n",
    "(\n",
    "    shapefile_list,\n",
    "    netcdf_list,\n",
    "    operator_list,\n",
    "    output_dir_list,\n",
    ") = construct_lists_for_parallel_function(NC4_DIR, SHAPE_DIR, OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf286115-13af-45d7-a47e-0bf6894cdb16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Test speed of parallel run\n",
    "run_function_parallel(shapefile_list, netcdf_list, operator_list, output_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb58ff-e83d-4076-8e82-1742a6efd138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
